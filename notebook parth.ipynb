{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd1e805-38c4-4f90-8d8a-53689dc86bbd",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881e5e1-39f1-4f06-b650-adaf3937564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pydantic import BaseModel\n",
    "from copy import deepcopy\n",
    "import threading\n",
    "import warnings\n",
    "import queue\n",
    "import json\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "JWT_SECRET_API = !echo $(aws --profile \"chat-prod_ro\" secretsmanager get-secret-value --secret-id \"arn:aws:secretsmanager:us-west-2:242659714806:secret:shared/cresta-server-jwt_secret-VDn5My\" --query SecretString --output text) # type: ignore\n",
    "os.environ[\"JWT_SECRET_API\"] = json.loads(JWT_SECRET_API[0])[\"jwt-secret\"]\n",
    "os.environ[\"CONFIG_SERVICE_ADDR\"] = \"auth.chat-prod.internal.cresta.ai:443\"\n",
    "os.environ[\"CONFIG_USE_SECURE_CHANNEL\"] = \"true\"\n",
    "\n",
    "# Third party imports\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from retry import retry\n",
    "\n",
    "# Greyparrot imports\n",
    "from greyparrot.llm.prompting import prompts as prompts_utils\n",
    "from greyparrot.conversations.db import ConversationsDBConn\n",
    "from greyparrot.multi_tenancy.v3_config import V3Config\n",
    "from greyparrot.conversations.utils import get_chats\n",
    "from greyparrot.chats_common import PartialChat\n",
    "from greyparrot.common import get_logger\n",
    "\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Local imports\n",
    "from llm_proxy_client import LLMProxyDevClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e4bd5d0-d369-4e36-92d6-a8d30198ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1a39f6-f947-40e6-8cc3-c129fe8610cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = \"brinks\"\n",
    "profile_id = \"care-voice\"\n",
    "usecase_id = \"care-voice\"\n",
    "language_code = \"en-US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5b2751-25c6-404f-9454-3747754271ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chats_with_ids(chat_ids: list[str]) -> list[PartialChat]:\n",
    "    customer_name: str = V3Config.short_name_from_ids(customer_id, profile_id)\n",
    "    conv_db_conn: ConversationsDBConn = ConversationsDBConn.from_customer_name(customer_name)\n",
    "    chats: list[PartialChat] = conv_db_conn.get_detailed_chats(\n",
    "        customer_id=customer_id,\n",
    "        profile_id=profile_id,\n",
    "        usecase_id=usecase_id,\n",
    "        language_code=language_code,\n",
    "        conversation_ids=chat_ids,\n",
    "        is_dev_user=False,\n",
    "    )\n",
    "    return chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afcb1094-7197-466c-8a03-d3725ccaf380",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_ENGINE: str = \"gpt-4o-mini\"\n",
    "CONCURRENCY: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620967f2-bf35-4305-9889-f08021619e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(tries=1, delay=60, backoff=2, logger=logger)\n",
    "def chat_completion(**kwargs):\n",
    "    return LLMProxyDevClient(\"openai\").beta.chat.completions.parse(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c40f7-e0e3-4eb8-818e-6a43d2d1dd02",
   "metadata": {},
   "source": [
    "# Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e404cd18-a964-45c5-8977-64053d53bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove this after fixing speaker_role flips\n",
    "flips: dict[str, str] = {\"agent\": \"visitor\", \"visitor\": \"agent\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d52de3a4-12a9-46a4-a930-5f14eb66db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_to_prompt_text(chat: PartialChat) -> str:\n",
    "    return \"\\n\".join([\n",
    "        f\"{prompts_utils.speaker_role_str_for_prompts(flips[m.speaker_role.value]).capitalize()}: {m.text}\"\n",
    "        for m in chat.messages\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099b0d7c-a431-4e1e-803a-2f69d8a1df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_AGENT_WORKFLOW_DISCOVERY = \"\"\"### Context and data description\n",
    "You are a conversation analyst working for Brinks Home Security Call Center.\n",
    "\n",
    "You will be given 1 conversation at a time. Each conversation is between a Brinks Call Center Agent and a Customer. Your primary goal is to extract workflows of steps which the Agent takes in **the given conversation** to help resolve the Customer's needs related to their home security system and services.\n",
    "\n",
    "The primary use case of these workflows is to create a troubleshooting template to address similar customer needs in the future.\n",
    "\n",
    "Each workflow should be a list of steps which the Agent needs to take.\n",
    "\n",
    "For each workflow, return:\n",
    "- Product: Specific Brinks product/service involved (e.g., Security Panel, Door/Window Sensor, Motion Detector, Security Camera, Doorbell Camera, Smart Lock, Mobile App, Alarm.com Account)\n",
    "- Issue: Specific customer problem (e.g., False Alarms, Device Offline, Camera Not Recording, App Login Issues, Billing Questions, Account Changes)\n",
    "- Steps: Detailed troubleshooting or resolution steps the Agent follows\n",
    "\n",
    "Make sure the product is specific to Brinks' security equipment and services, not general categories.\n",
    "Make sure the issue clearly describes the exact problem the customer is experiencing.\n",
    "Make sure the steps are detailed and follow Brinks' standard operating procedures.\n",
    "Make sure to only return the agent troubleshooting steps, not the customer's requests or other information.\n",
    "\n",
    "Common scenarios include:\n",
    "- Security system troubleshooting (panel issues, sensor malfunctions, connectivity problems)\n",
    "- Camera and video recording issues\n",
    "- Account management (billing, autopay, contact updates)\n",
    "- Mobile app and Alarm.com portal assistance\n",
    "- Service changes (moving, upgrading, cancellation)\n",
    "- Installation and maintenance appointments\n",
    "\n",
    "**Important**: There could be more than 1 workflow in a single conversation. There could also be no workflows in a single conversation. The workflows will be used to create troubleshooting guides to address similar customer needs in the future.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b37c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(BaseModel):\n",
    "    product: str\n",
    "    issue: str\n",
    "    steps: list[str]\n",
    "\n",
    "class Flows(BaseModel):\n",
    "    flows: list[Flow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64e4a2f3-1e34-43ee-94e2-65015660af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_flow_in_chat(chat: PartialChat,\n",
    "                          llm_engine: str = LLM_ENGINE) -> list[Flow]:\n",
    "    logger.info(f\"Discovering Agent flow in chat {chat.chat_name}\")\n",
    "    messages: list[dict[str, str]] = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": SYSTEM_PROMPT_AGENT_WORKFLOW_DISCOVERY\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": chat_to_prompt_text(chat)\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return chat_completion(model=llm_engine,\n",
    "                            messages=messages,\n",
    "                            response_format=Flows).choices[0].message.parsed.flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "034f33d5-e6fe-49f4-918b-6a88819af747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flows_from_chats(chats: list[PartialChat],\n",
    "                                concurrency: int=10) -> dict[str, list[Flow]]:\n",
    "    lock: threading.Lock = threading.Lock()\n",
    "    indexes: queue.Queue = queue.Queue()\n",
    "\n",
    "    workflows: dict[str, list[Flow]] = {}\n",
    "    for idx in range(len(chats)):\n",
    "        indexes.put(idx)\n",
    "\n",
    "    def workflow_labeler_worker():\n",
    "        while True:\n",
    "            try:\n",
    "                idx = indexes.get(block=False)\n",
    "            except queue.Empty:\n",
    "                return\n",
    "            chat = chats[idx]\n",
    "            try:\n",
    "                extracted_workflows: list[Flow] = discover_flow_in_chat(chat)\n",
    "                with lock:\n",
    "                    workflows[str(chat)] = extracted_workflows\n",
    "                    if len(workflows) % 10 == 0:\n",
    "                        print(f\"Workflows from {len(workflows)} chats extracted!\")\n",
    "            except Exception as e:\n",
    "                logger.warning(e, str(chat))\n",
    "            indexes.task_done()\n",
    "\n",
    "    logger.info(\n",
    "        f\"Starting processing {len(chats)} chats with {concurrency} workers\")\n",
    "    workers = [\n",
    "        threading.Thread(target=workflow_labeler_worker)\n",
    "        for _ in range(concurrency)\n",
    "    ]\n",
    "    # Start all workers\n",
    "    for worker in workers:\n",
    "        worker.start()\n",
    "    for worker in workers:\n",
    "        worker.join()\n",
    "    logger.info(f\"Finished processing all {len(chats)} chats\")\n",
    "\n",
    "    return workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefb919-3d2e-4cea-a6f2-f593a3e251ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_chat: PartialChat = get_chats_with_ids([\"0843c54c-6487-45ce-946a-cc6257484f54\"])[0]\n",
    "workflows: list[Flow] = discover_flow_in_chat(test_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1238bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_to_prompt_text(test_chat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6064d-1c44-4811-9245-d5e83d838178",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(workflows)} workflows\\n\")\n",
    "for i, flow in enumerate(workflows):\n",
    "    print(f\"[Agent Workflow #{i + 1}]\")\n",
    "    print(f\"Product: {flow.product}\")\n",
    "    print(f\"Issue: {flow.issue}\")\n",
    "    print(\"Steps:\", end=\"\\n* \")\n",
    "    print(\"\\n* \".join(flow.steps))\n",
    "    if i < len(workflows) - 1:\n",
    "        print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593f36c-c4c0-4fac-9e09-b64e0f8d65d2",
   "metadata": {},
   "source": [
    "# 200 Recent Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = get_chats(\n",
    "    'brinks-care-voice', \n",
    "    '2024-06-01',\n",
    "    '2024-12-01',\n",
    "    200,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47768b-bd30-4000-8dc2-73dc170bd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_chat_ids = list(set([\n",
    "    chat.chat_name\n",
    "    for chat in (item if not isinstance(item, tuple) else item[0] for item in data_set)\n",
    "    if hasattr(chat, 'chat_name')\n",
    "]))\n",
    "print(len(sampled_chat_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04fb3d-0c9e-4a97-b074-c967ef49f05b",
   "metadata": {},
   "source": [
    "# Agent Workflow Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_chats = get_chats_with_ids(sampled_chat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc0f6fa-e10a-41cf-bffc-04e6138493bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflows = extract_flows_from_chats(sampled_chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f33c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(w) for w in workflows.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "229e9766",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_workflows = []\n",
    "for w in workflows.values():\n",
    "    all_workflows.extend(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343fee9",
   "metadata": {},
   "source": [
    "# Grouping Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bfb615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_workflows_by_product(workflows: list[Flow], embedder: SentenceTransformer, semantic_threshold: float) -> dict[str, list[Flow]]:\n",
    "    \n",
    "    products = [w.product for w in workflows]\n",
    "    embeddings = embedder.encode(products, convert_to_tensor=True)\n",
    "        \n",
    "    product_groups, solo_products = [], []\n",
    "    for idx, _ in enumerate(products):\n",
    "        existing_groups = [group for group in product_groups if idx in group]\n",
    "        if existing_groups:\n",
    "            assert len(\n",
    "                existing_groups) == 1, \"A workflow should only be in 1 group\"\n",
    "            continue\n",
    "\n",
    "        scores = util.cos_sim(embeddings[idx:idx + 1],\n",
    "                              embeddings).cpu().tolist()[0]\n",
    "        matches = [\n",
    "            i for i, score in enumerate(scores) if score > semantic_threshold\n",
    "        ]\n",
    "        filtered_matches = [i for i in matches if i != idx]\n",
    "        if filtered_matches:\n",
    "            outstanding_groups = []\n",
    "            new_group = filtered_matches + [idx]\n",
    "            for group in product_groups:\n",
    "                if set(filtered_matches).intersection(set(group)):\n",
    "                    new_group.extend(group)\n",
    "                else:\n",
    "                    outstanding_groups.append(group)\n",
    "            product_groups = outstanding_groups + [list(set(new_group))]\n",
    "        else:\n",
    "            solo_products.append(idx)\n",
    "\n",
    "    print(f\"Found {len(solo_products)} # of Solo Products.\")\n",
    "    print(f\"Found {len(product_groups)} # Groups of Products.\")\n",
    "\n",
    "    # Create mapping of indices to product names\n",
    "    idx_to_product = {i: p for i, p in enumerate(products)}\n",
    "    \n",
    "    retval = {}\n",
    "\n",
    "    for group in product_groups:\n",
    "        group_key = tuple(set([idx_to_product[idx] for idx in group]))\n",
    "        retval[group_key] = [workflows[idx] for idx in group]\n",
    "\n",
    "    for idx in solo_products:\n",
    "        retval[(workflows[idx].product,)] = [workflows[idx]]\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43995c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_workflows_by_issues(workflows: list[Flow], embedder: SentenceTransformer, semantic_threshold: float) -> dict[tuple[str], list[Flow]]:\n",
    "    \n",
    "    issues = [w.issue for w in workflows]\n",
    "    embeddings = embedder.encode(issues, convert_to_tensor=True)\n",
    "        \n",
    "    issue_groups, solo_issues = [], []\n",
    "    for idx, _ in enumerate(issues):\n",
    "        existing_groups = [group for group in issue_groups if idx in group]\n",
    "        if existing_groups:\n",
    "            assert len(\n",
    "                existing_groups) == 1, \"A workflow should only be in 1 group\"\n",
    "            continue\n",
    "\n",
    "        scores = util.cos_sim(embeddings[idx:idx + 1],\n",
    "                              embeddings).cpu().tolist()[0]\n",
    "        matches = [\n",
    "            i for i, score in enumerate(scores) if score > semantic_threshold\n",
    "        ]\n",
    "        filtered_matches = [i for i in matches if i != idx]\n",
    "        if filtered_matches:\n",
    "            outstanding_groups = []\n",
    "            new_group = filtered_matches + [idx]\n",
    "            for group in issue_groups:\n",
    "                if set(filtered_matches).intersection(set(group)):\n",
    "                    new_group.extend(group)\n",
    "                else:\n",
    "                    outstanding_groups.append(group)\n",
    "            issue_groups = outstanding_groups + [list(set(new_group))]\n",
    "        else:\n",
    "            solo_issues.append(idx)\n",
    "\n",
    "    print(f\"Found {len(solo_issues)} # of Solo Issues.\")\n",
    "    print(f\"Found {len(issue_groups)} # Groups of Issues.\")\n",
    "\n",
    "    # Create mapping of indices to product names\n",
    "    idx_to_issue = {i: p for i, p in enumerate(issues)}\n",
    "    \n",
    "    retval = {}\n",
    "\n",
    "    for group in issue_groups:\n",
    "        group_key = tuple(set([idx_to_issue[idx] for idx in group]))\n",
    "        retval[group_key] = [workflows[idx] for idx in group]\n",
    "\n",
    "    for idx in solo_issues:\n",
    "        retval[(workflows[idx].issue,)] = [workflows[idx]]\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811eb663-b988-4de3-90c7-3db995d55780",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = group_workflows_by_product(all_workflows, embedder, semantic_threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in tree.keys():\n",
    "    tree[product] = group_workflows_by_issues(tree[product], embedder, semantic_threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4513fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "leafs = 0\n",
    "for product in tree.keys():\n",
    "    for issue in tree[product].keys():\n",
    "        leafs += 1\n",
    "print(f\"Found {leafs} leafs in the tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    "    \"camera\": [camera_flow1, camera_flow2, camera_flow3],\n",
    "    \"alarm\": [alarm_flow4, alarm_flow5, alarm_flow6],\n",
    "    \"TV\": [tv_flow1]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "{\n",
    "    \"camera\": {\n",
    "        \"issue1\": [camera_issue1_flow1, camera_issue1_flow2, camera_issue1_flow3],\n",
    "        \"issue2\": [camera_issue2_flow1, camera_issue2_flow2, camera_issue2_flow3],\n",
    "    },\n",
    "    \"alarm\": {\n",
    "        \"issue1\": [alarm_issue1_flow1, alarm_issue1_flow2, alarm_issue1_flow3],\n",
    "        \"issue2\": [alarm_issue2_flow1, alarm_issue2_flow2, alarm_issue2_flow3],\n",
    "    },\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "{\n",
    "    \"camera\": {\n",
    "        \"issue1\": troubleshooting_steps,\n",
    "        \"issue2\": troubleshooting_steps,\n",
    "    },\n",
    "    \"alarm\": {\n",
    "        \"issue1\": troubleshooting_steps,\n",
    "        \"issue2\": troubleshooting_steps,\n",
    "    },\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ad87a",
   "metadata": {},
   "source": [
    "# Generate Troubleshooting Guide for each leaf in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "285d5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TroubleshootingGuide(BaseModel):\n",
    "    steps: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "145c0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_flows(flows: list[Flow]) -> str:\n",
    "    conversations = []\n",
    "    for i, flow in enumerate(flows):\n",
    "        conversation = f\"Conversation {i+1}:\\n\" + \"\\n\".join(f\"* {step}\" for step in flow.steps)\n",
    "        conversations.append(conversation)\n",
    "    return \"\\n\\n\".join(conversations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34c7ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_TROUBLESHOOTING_GUIDE_PROMPT = \"\"\"\\\n",
    "You are a conversation analyst working for Brinks Home Security Call Center.\n",
    "\n",
    "You will be given the troubleshooting steps taken by a call center agent of 1 or more conversations at a time. Your primary goal is to generate an overall troubleshooting guide for the given product and issue.\n",
    "\n",
    "The troubleshooting guide must consider all scenarios and steps from the given conversations. Do not produce any steps that are not present in the given conversations. Only produce an overall troubleshooting guide after gaining information from all the conversations.\n",
    "\n",
    "You must produce an ordered list of steps that the agent can follow to help resolve the customer's needs related to the product and issue.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0da878b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_troubleshooting_guide(product: str, issue: str, llm_engine: str = LLM_ENGINE) -> str:\n",
    "    messages: list[dict[str, str]] = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": GENERATE_TROUBLESHOOTING_GUIDE_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": concatenate_flows(tree[product][issue])\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return chat_completion(model=llm_engine,\n",
    "                            messages=messages,\n",
    "                            response_format=TroubleshootingGuide).choices[0].message.parsed.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18bb74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_troubleshooting_guides(tree: dict[str, dict[str, list[Flow]]], llm_engine: str = LLM_ENGINE, concurrency: int=10) -> None:\n",
    "    lock: threading.Lock = threading.Lock()\n",
    "    indexes: queue.Queue = queue.Queue()\n",
    "    \n",
    "    # Create flat list of (product, issue) pairs to process\n",
    "    tasks = []\n",
    "    for product in tree.keys():\n",
    "        for issue in tree[product].keys():\n",
    "            tasks.append((product, issue))\n",
    "            \n",
    "    for idx in range(len(tasks)):\n",
    "        indexes.put(idx)\n",
    "\n",
    "    def troubleshooting_guide_worker():\n",
    "        while True:\n",
    "            try:\n",
    "                idx = indexes.get(block=False)\n",
    "            except queue.Empty:\n",
    "                return\n",
    "                \n",
    "            product, issue = tasks[idx]\n",
    "            try:\n",
    "                guide = generate_troubleshooting_guide(product, issue, llm_engine)\n",
    "                with lock:\n",
    "                    tree[product][issue] = guide\n",
    "                if idx % 10 == 0:\n",
    "                    print(f\"Generated guides for {idx} product/issue pairs\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error generating guide for {product}/{issue}: {e}\")\n",
    "            indexes.task_done()\n",
    "\n",
    "    logger.info(f\"Starting guide generation for {len(tasks)} product/issue pairs\")\n",
    "    workers = [\n",
    "        threading.Thread(target=troubleshooting_guide_worker)\n",
    "        for _ in range(concurrency)\n",
    "    ]\n",
    "    for worker in workers:\n",
    "        worker.start()\n",
    "    for worker in workers:\n",
    "        worker.join()\n",
    "    logger.info(\"Finished generating all guides\")\n",
    "    print(\"Finished generating all guides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ef4f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "troubleshooting_guide = deepcopy(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d550b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_troubleshooting_guides(troubleshooting_guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f22df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in troubleshooting_guide.keys():\n",
    "    print(f\"Product: {product}\")\n",
    "    print(f\"{'-'*100}\\n{'-'*100}\")\n",
    "    for issue in troubleshooting_guide[product].keys():\n",
    "        print(f\"**Issue: {issue}**\")\n",
    "        print(\"\\n\".join(troubleshooting_guide[product][issue]))\n",
    "        print(\"-\"*100)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76251661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to export troubleshooting guide to Markdown\n",
    "def export_to_markdown(troubleshooting_guide, output_file=\"troubleshooting_guide.md\"):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for product in troubleshooting_guide.keys():\n",
    "            f.write(f\"# Product: {product}\\n\")\n",
    "            for issue in troubleshooting_guide[product].keys():\n",
    "                # Write issue and steps\n",
    "                f.write(f\"## **Issue: {issue}**\\n\\n\")\n",
    "                f.write(\"\\n\".join([f\"- {step}\" for step in troubleshooting_guide[product][issue]]) + \"\\n\")\n",
    "\n",
    "# Example: Export the existing troubleshooting_guide\n",
    "export_to_markdown(troubleshooting_guide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38f894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
